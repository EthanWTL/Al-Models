{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd632928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==1.7.1\n",
    "# pip install transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b53a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16340006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version                                               data\n",
       "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
       "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
       "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
       "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
       "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
    "coqa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662b89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del coqa['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ce5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required columns in our dataframe\n",
    "cols = [\"text\",\"question\",\"answer\"]\n",
    "#list of lists to create our dataframe\n",
    "comp_list = []\n",
    "for index, row in coqa.iterrows():\n",
    "    for i in range(len(row[\"data\"][\"questions\"])):\n",
    "        temp_list = []\n",
    "        temp_list.append(row[\"data\"][\"story\"])\n",
    "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
    "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
    "        comp_list.append(temp_list)\n",
    "new_df = pd.DataFrame(comp_list, columns=cols) \n",
    "#saving the dataframe to csv file for further loading\n",
    "new_df.to_csv(\"CoQA_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7af9f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Vatican Apostolic Library (), more commonly called the Vatican Library or simply the Vat, is the library of the Holy See, located in Vatican City. Formally established in 1475, although it is much older, it is one of the oldest libraries in the world and contains one of the most significant collections of historical texts. It has 75,000 codices from throughout history, as well as 1.1 million printed books, which include some 8,500 incunabula. \\n\\nThe Vatican Library is a research library for history, law, philosophy, science and theology. The Vatican Library is open to anyone who can document their qualifications and research needs. Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail. \\n\\nIn March 2014, the Vatican Library began an initial four-year project of digitising its collection of manuscripts, to be made available online. \\n\\nThe Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items. \\n\\nScholars have traditionally divided the history of the library into five periods, Pre-Lateran, Lateran, Avignon, Pre-Vatican and Vatican. \\n\\nThe Pre-Lateran period, comprising the initial days of the library, dated from the earliest days of the Church. Only a handful of volumes survive from this period, though some are very significant.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb6d7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                            question                               answer  \n",
       "0  When was the Vat formally opened?  It was formally established in 1475  \n",
       "1           what is the library for?                             research  \n",
       "2                 for what subjects?                     history, and law  \n",
       "3                               and?     philosophy, science and theology  \n",
       "4          what was started in 2014?                           a  project  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"CoQA_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff22564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question and answers:  108647\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of question and answers: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25c4259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "716e40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0,len(data))\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e863d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 370 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db7ff777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "was        2,001\n",
      "he         2,002\n",
      "alive      4,142\n",
      "300        3,998\n",
      "years      2,086\n",
      "ago        3,283\n",
      "?          1,029\n",
      "[SEP]        102\n",
      "charles    2,798\n",
      "dickens   19,675\n",
      "is         2,003\n",
      "often      2,411\n",
      "thought    2,245\n",
      "of         1,997\n",
      "as         2,004\n",
      "one        2,028\n",
      "of         1,997\n",
      "the        1,996\n",
      "greatest   4,602\n",
      "british    2,329\n",
      "writers    4,898\n",
      ".          1,012\n",
      "february   2,337\n",
      "7          1,021\n",
      "marked     4,417\n",
      "the        1,996\n",
      "200        3,263\n",
      "##th       2,705\n",
      "anniversary   5,315\n",
      "of         1,997\n",
      "his        2,010\n",
      "birthday   5,798\n",
      ".          1,012\n",
      "yet        2,664\n",
      "for        2,005\n",
      "many       2,116\n",
      ",          1,010\n",
      "his        2,010\n",
      "language   2,653\n",
      "is         2,003\n",
      "old        2,214\n",
      "-          1,011\n",
      "fashioned  13,405\n",
      "and        1,998\n",
      "his        2,010\n",
      "stories    3,441\n",
      "often      2,411\n",
      "imp       17,727\n",
      "##ro       3,217\n",
      "##ba       3,676\n",
      "##ble      3,468\n",
      ".          1,012\n",
      "so         2,061\n",
      "why        2,339\n",
      "do         2,079\n",
      "so         2,061\n",
      "many       2,116\n",
      "people     2,111\n",
      "know       2,113\n",
      "and        1,998\n",
      "read       3,191\n",
      "dickens   19,675\n",
      "today      2,651\n",
      "?          1,029\n",
      "one        2,028\n",
      "reason     3,114\n",
      "is         2,003\n",
      "the        1,996\n",
      "british    2,329\n",
      "government   2,231\n",
      "'          1,005\n",
      "s          1,055\n",
      "insistence  20,616\n",
      "that       2,008\n",
      "every      2,296\n",
      "child      2,775\n",
      "studies    2,913\n",
      "a          1,037\n",
      "dickens   19,675\n",
      "novel      3,117\n",
      "at         2,012\n",
      "school     2,082\n",
      ".          1,012\n",
      "alongside   4,077\n",
      "william    2,520\n",
      "shakespeare   8,101\n",
      ",          1,010\n",
      "dickens   19,675\n",
      "is         2,003\n",
      "on         2,006\n",
      "every      2,296\n",
      "english    2,394\n",
      "literature   3,906\n",
      "school     2,082\n",
      "reading    3,752\n",
      "list       2,862\n",
      ".          1,012\n",
      "his        2,010\n",
      "stories    3,441\n",
      ",          1,010\n",
      "though     2,295\n",
      "often      2,411\n",
      "long       2,146\n",
      "by         2,011\n",
      "today      2,651\n",
      "'          1,005\n",
      "s          1,055\n",
      "standards   4,781\n",
      ",          1,010\n",
      "are        2,024\n",
      "great      2,307\n",
      "moral      7,191\n",
      "tales      7,122\n",
      ".          1,012\n",
      "they       2,027\n",
      "are        2,024\n",
      "filled     3,561\n",
      "with       2,007\n",
      "colorful  14,231\n",
      "characters   3,494\n",
      ".          1,012\n",
      "earlier    3,041\n",
      "this       2,023\n",
      "month      3,204\n",
      ",          1,010\n",
      "a          1,037\n",
      "ceremony   5,103\n",
      "was        2,001\n",
      "held       2,218\n",
      "in         1,999\n",
      "portsmouth  10,913\n",
      ",          1,010\n",
      "where      2,073\n",
      "dickens   19,675\n",
      "was        2,001\n",
      "born       2,141\n",
      ".          1,012\n",
      "prince     3,159\n",
      "charles    2,798\n",
      "said       2,056\n",
      "at         2,012\n",
      "the        1,996\n",
      "ceremony   5,103\n",
      ",          1,010\n",
      "\"          1,000\n",
      "dickens   19,675\n",
      "used       2,109\n",
      "his        2,010\n",
      "creative   5,541\n",
      "genius    11,067\n",
      "to         2,000\n",
      "campaign   3,049\n",
      "passionate  13,459\n",
      "##ly       2,135\n",
      "for        2,005\n",
      "social     2,591\n",
      "justice    3,425\n",
      ".          1,012\n",
      ".          1,012\n",
      ".          1,012\n",
      "his        2,010\n",
      "characterization  23,191\n",
      "is         2,003\n",
      "as         2,004\n",
      "fresh      4,840\n",
      "today      2,651\n",
      "as         2,004\n",
      "on         2,006\n",
      "the        1,996\n",
      "day        2,154\n",
      "it         2,009\n",
      "was        2,001\n",
      "written    2,517\n",
      ".          1,012\n",
      "\"          1,000\n",
      "his        2,010\n",
      "books      2,808\n",
      "stand      3,233\n",
      "out        2,041\n",
      "from       2,013\n",
      "many       2,116\n",
      "other      2,060\n",
      "writers    4,898\n",
      "because    2,138\n",
      "of         1,997\n",
      "his        2,010\n",
      "insight   12,369\n",
      "into       2,046\n",
      "human      2,529\n",
      "nature     3,267\n",
      ".          1,012\n",
      "dickens   19,675\n",
      ",          1,010\n",
      "like       2,066\n",
      "shakespeare   8,101\n",
      ",          1,010\n",
      "tells      4,136\n",
      "us         2,149\n",
      "truths    23,019\n",
      "about      2,055\n",
      "human      2,529\n",
      "behavior   5,248\n",
      ".          1,012\n",
      "they       2,027\n",
      "are        2,024\n",
      "as         2,004\n",
      "true       2,995\n",
      "in         1,999\n",
      "the        1,996\n",
      "21st       7,398\n",
      "century    2,301\n",
      "as         2,004\n",
      "they       2,027\n",
      "were       2,020\n",
      "to         2,000\n",
      "his        2,010\n",
      "readers    8,141\n",
      "in         1,999\n",
      "the        1,996\n",
      "19th       3,708\n",
      "century    2,301\n",
      ".          1,012\n",
      "readers    8,141\n",
      "have       2,031\n",
      "returned   2,513\n",
      "to         2,000\n",
      "dickens   19,675\n",
      "'          1,005\n",
      "books      2,808\n",
      "again      2,153\n",
      "and        1,998\n",
      "again      2,153\n",
      "over       2,058\n",
      "the        1,996\n",
      "years      2,086\n",
      "to         2,000\n",
      "see        2,156\n",
      "what       2,054\n",
      "he         2,002\n",
      "has        2,038\n",
      "to         2,000\n",
      "say        2,360\n",
      "about      2,055\n",
      "their      2,037\n",
      "own        2,219\n",
      "times      2,335\n",
      ".          1,012\n",
      "no         2,053\n",
      "surprise   4,474\n",
      "then       2,059\n",
      "that       2,008\n",
      "it         2,009\n",
      "was        2,001\n",
      "dickens   19,675\n",
      "whom       3,183\n",
      "brit      28,101\n",
      "##ons      5,644\n",
      "turned     2,357\n",
      "to         2,000\n",
      "during     2,076\n",
      "the        1,996\n",
      "economic   3,171\n",
      "crisis     5,325\n",
      "in         1,999\n",
      "the        1,996\n",
      "last       2,197\n",
      "couple     3,232\n",
      "of         1,997\n",
      "years      2,086\n",
      ".          1,012\n",
      "dickens   19,675\n",
      "helped     3,271\n",
      "them       2,068\n",
      "make       2,191\n",
      "sense      3,168\n",
      "of         1,997\n",
      "a          1,037\n",
      "world      2,088\n",
      "that       2,008\n",
      "was        2,001\n",
      "rapidly    5,901\n",
      "falling    4,634\n",
      "apart      4,237\n",
      ".          1,012\n",
      "the        1,996\n",
      "bbc        4,035\n",
      "adapted    5,967\n",
      "one        2,028\n",
      "of         1,997\n",
      "his        2,010\n",
      "less       2,625\n",
      "well       2,092\n",
      "-          1,011\n",
      "known      2,124\n",
      "novels     6,002\n",
      ",          1,010\n",
      "little     2,210\n",
      "do         2,079\n",
      "##rri     18,752\n",
      "##t        2,102\n",
      ",          1,010\n",
      "into       2,046\n",
      "a          1,037\n",
      "popular    2,759\n",
      "television   2,547\n",
      "drama      3,689\n",
      "that       2,008\n",
      "introduced   3,107\n",
      "many       2,116\n",
      "brit      28,101\n",
      "##s        2,015\n",
      "to         2,000\n",
      "the        1,996\n",
      "novel      3,117\n",
      "for        2,005\n",
      "the        1,996\n",
      "first      2,034\n",
      "time       2,051\n",
      ".          1,012\n",
      "a          1,037\n",
      "dark       2,601\n",
      "story      2,466\n",
      "about      2,055\n",
      "greed     22,040\n",
      "and        1,998\n",
      "money      2,769\n",
      ",          1,010\n",
      "it         2,009\n",
      "was        2,001\n",
      "the        1,996\n",
      "perfect    3,819\n",
      "illustration  14,614\n",
      "of         1,997\n",
      "bad        2,919\n",
      "times      2,335\n",
      ".          1,012\n",
      "as         2,004\n",
      "long       2,146\n",
      "as         2,004\n",
      "dickens   19,675\n",
      "'          1,005\n",
      "s          1,055\n",
      "novels     6,002\n",
      "have       2,031\n",
      "something   2,242\n",
      "to         2,000\n",
      "say        2,360\n",
      "to         2,000\n",
      "modern     2,715\n",
      "audiences   9,501\n",
      ",          1,010\n",
      "it         2,009\n",
      "seems      3,849\n",
      "likely     3,497\n",
      "that       2,008\n",
      "he         2,002\n",
      "will       2,097\n",
      "remain     3,961\n",
      "one        2,028\n",
      "of         1,997\n",
      "britain    3,725\n",
      "'          1,005\n",
      "s          1,055\n",
      "best       2,190\n",
      "-          1,011\n",
      "loved      3,866\n",
      "writers    4,898\n",
      ".          1,012\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print('{:8}{:8,}'.format(token,id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ce3c82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEP token index:  8\n",
      "Number of tokens in segment A:  9\n",
      "Number of tokens in segment B:  361\n"
     ]
    }
   ],
   "source": [
    "#first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(\"SEP token index: \", sep_idx)\n",
    "#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
    "num_seg_a = sep_idx+1\n",
    "print(\"Number of tokens in segment A: \", num_seg_a)\n",
    "#number of tokens in segment B (text)\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(\"Number of tokens in segment B: \", num_seg_b)\n",
    "#creating the segment ids\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "#making sure that every input token has a segment id\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc3a9df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c5e63dc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ca4fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token input_ids to represent the input and token segment_ids to differentiate our segments - question and text\n",
    "output = model(torch.tensor([input_ids]), \n",
    "token_type_ids=torch.tensor([segment_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd491f3c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am unable to find the answer to this question. Can you please ask another question?\n",
      "\n",
      "Question:\n",
      "Was he alive 300 years ago?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am unable to find the answer to this question. Can you please ask another question?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuestion:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m.\u001b[39mcapitalize()))\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43manswer\u001b[49m\u001b[38;5;241m.\u001b[39mcapitalize()))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'answer' is not defined"
     ]
    }
   ],
   "source": [
    "#tokens with highest start and end scores\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "print(answer_start)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "print(answer_end)\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69e5a7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "(CNN) -- The biological mother of a missing 7-year-old Oregon boy has written an open letter to her son saying, \"I am sorry that I was not there to protect you.\" \n",
      "\n",
      "\"I am so soooooo sorry that this has happened,\" Desiree Young wrote to Kyron Horman in a letter that was released Monday to NBC News. \n",
      "\n",
      "\"I will never be able to forgive myself for being so many hours away when you needed me the most. I pray that you come back to me because I am afraid that I can't live without you.\" \n",
      "\n",
      "The letter comes more than two weeks after the boy disappeared on June 4. \n",
      "\n",
      "The boy's stepmother, Terri Horman, said she last saw Kyron walking down the hallway towards his classroom at Skyline Elementary School, police said. Cell phone records indicate she may not have been at the school at that time, according to a report in People Magazine. Authorities refused to comment on the report. \n",
      "\n",
      "In the emotional letter, Young speaks directly to her young son. \"When you come home I will show you all of [the] things that everyone did for you, just to find you,\" she wrote. \n",
      "\n",
      "\"There are literally hundreds of thousands of people that don't know you and yet they pray for you every night. They know how much I miss you and need you and they just want to bring you home to me. There are so many wonderful people working on this case and they are going to find you soon. \n"
     ]
    }
   ],
   "source": [
    "random_num = np.random.randint(0,len(data))\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81c8045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2073, 2515, 7658, 2817, 2012, 1029, 102, 19337, 28100, 2267, 2003, 1037, 3835, 2082, 1012, 2045, 2024, 1037, 2843, 1997, 2493, 2066, 6066, 1998, 4463, 1012, 4463, 2817, 2012, 19337, 28100, 2267, 1012, 7658, 2817, 2012, 5284, 2267, 102]\n",
      "['[CLS]', 'where', 'does', 'han', 'study', 'at', '?', '[SEP]', 'bel', '##oit', 'college', 'is', 'a', 'nice', 'school', '.', 'there', 'are', 'a', 'lot', 'of', 'students', 'like', 'ethan', 'and', 'jason', '.', 'jason', 'study', 'at', 'bel', '##oit', 'college', '.', 'han', 'study', 'at', 'missouri', 'college', '[SEP]']\n",
      "tensor(37)\n",
      "tensor(38)\n",
      "\n",
      "Question:\n",
      "Where does han study at?\n",
      "\n",
      "Answer:\n",
      "Missouri college.\n"
     ]
    }
   ],
   "source": [
    "#random_num = np.random.randint(0,len(data))\n",
    "#question = data[\"question\"][random_num]\n",
    "#text = data[\"text\"][random_num]\n",
    "\n",
    "question='Where does Han study at?'\n",
    "text='Beloit College is a nice school. There are a lot of students like Ethan and Jason. Jason Study at Beloit College. Han study at Missouri College'\n",
    "\n",
    "input_ids = tokenizer.encode(question, text)\n",
    "print(input_ids)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(tokens)\n",
    "#first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
    "num_seg_a = sep_idx+1\n",
    "#number of tokens in segment B (text)\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "#creating the segment ids\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "#making sure that every input token has a segment id\n",
    "assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "output = model(torch.tensor([input_ids]), \n",
    "token_type_ids=torch.tensor([segment_ids]))\n",
    "\n",
    "#tokens with highest start and end scores\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "print(answer_start)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "print(answer_end)\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ec69a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text:\n",
      "Beloit college is a nice school. there are a lot of students. ethan study at beloit college. han study at missouri college\n",
      "\n",
      "Question:\n",
      "Where was he from?\n",
      "\n",
      "Answer:\n",
      "Missouri.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nText:\\n{}\".format(text.capitalize()))\n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573d0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
